# LocalChatBot-Using-Ollama
 This is my first project on github. With the new wave of AI, I decided to download a local LLM on my machine, and configure it using python to have my own chatbot that stores conversation memory per run, rather than storing all my inputs over time. This is useful for simple calculations, explanations etc instead of scouring google for a vague answer
